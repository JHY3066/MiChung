{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# KMU Comovement â€” Pair Classifier Only\n",
        "#  - (A,B) 9900ìŒì— ëŒ€í•´ ê³µí–‰ì„± í™•ë¥  comov_prob ì˜ˆì¸¡\n",
        "#  - ì•„ì§ value ì˜ˆì¸¡(íšŒê·€)ì€ ì•ˆ í•¨\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "DATA_DIR = Path(\".\")\n",
        "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
        "SUB_PATH   = DATA_DIR / \"sample_submission.csv\"\n",
        "\n",
        "# ì´ì „ ì œì¶œë¬¼ë“¤ (pseudo-labelìš©)\n",
        "PSEUDO_FILES = [\n",
        "    \"v3_lightgbm_submission.csv\",\n",
        "    \"submission 0.3.csv\",\n",
        "]\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1. ë°ì´í„° ë¡œë“œ + ì›”ë³„ ì§‘ê³„ (panel)\n",
        "# ============================================================\n",
        "print(\"â–¶ Loading data...\")\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "sub   = pd.read_csv(SUB_PATH)\n",
        "\n",
        "assert {\"item_id\", \"year\", \"month\", \"value\"}.issubset(train.columns)\n",
        "assert {\"leading_item_id\", \"following_item_id\"}.issubset(sub.columns)\n",
        "\n",
        "# year-month â†’ date\n",
        "train[\"date\"] = pd.to_datetime(\n",
        "    dict(year=train[\"year\"], month=train[\"month\"], day=1)\n",
        ")\n",
        "\n",
        "# ì›”ë³„ value í•©\n",
        "monthly = (\n",
        "    train.groupby([\"item_id\", \"date\"], as_index=False)[\"value\"]\n",
        "         .sum()\n",
        ")\n",
        "\n",
        "# íŒ¨ë„: index=date, columns=item_id\n",
        "panel = monthly.pivot(index=\"date\", columns=\"item_id\", values=\"value\").sort_index()\n",
        "print(f\"  - panel shape = {panel.shape}\")  # (n_months, n_items)\n",
        "\n",
        "dates = panel.index\n",
        "items = panel.columns.tolist()\n",
        "\n",
        "# itemë³„ hs4, hs2\n",
        "if \"hs4\" in train.columns:\n",
        "    item_hs4 = train.groupby(\"item_id\")[\"hs4\"].first().to_dict()\n",
        "else:\n",
        "    item_hs4 = {i: None for i in items}\n",
        "\n",
        "def get_hs2(hs4):\n",
        "    if pd.isna(hs4):\n",
        "        return None\n",
        "    s = str(hs4)\n",
        "    return s[:2]\n",
        "\n",
        "item_hs2 = {i: get_hs2(item_hs4.get(i, None)) for i in items}\n",
        "\n",
        "# active ratio (ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í•˜ëŠ”ì§€)\n",
        "total_months = len(panel.index)\n",
        "active_ratio = (panel.notna().sum(axis=0) / total_months).to_dict()\n",
        "\n",
        "# ê³„ì ˆ íŒ¨í„´ (itemë³„ monthâ†’í‰ê·  value â†’ cosine similarity)\n",
        "monthly_tmp = monthly.copy()\n",
        "monthly_tmp[\"month_num\"] = monthly_tmp[\"date\"].dt.month\n",
        "seasonal = monthly_tmp.groupby([\"item_id\", \"month_num\"])[\"value\"].mean().unstack(\"month_num\").fillna(0.0)\n",
        "seasonal_norm = seasonal.div(seasonal.sum(axis=1).replace(0,1), axis=0)\n",
        "\n",
        "def seasonal_sim(A, B):\n",
        "    if (A not in seasonal_norm.index) or (B not in seasonal_norm.index):\n",
        "        return 0.0\n",
        "    vA = seasonal_norm.loc[A].values\n",
        "    vB = seasonal_norm.loc[B].values\n",
        "    num = float((vA * vB).sum())\n",
        "    den = float(np.linalg.norm(vA) * np.linalg.norm(vB))\n",
        "    return float(num / den) if den > 0 else 0.0\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. ì´ì „ ì œì¶œë¬¼ë“¤ì—ì„œ pair ë“±ì¥ íšŸìˆ˜ (appear_cnt)\n",
        "# ============================================================\n",
        "print(\"â–¶ Loading previous submissions for appear_cnt...\")\n",
        "pair_appear = defaultdict(int)\n",
        "\n",
        "for fname in PSEUDO_FILES:\n",
        "    p = DATA_DIR / fname\n",
        "    if not p.exists():\n",
        "        print(f\"  - {fname} not found, skip.\")\n",
        "        continue\n",
        "    df_sub = pd.read_csv(p)\n",
        "    if not {\"leading_item_id\", \"following_item_id\"}.issubset(df_sub.columns):\n",
        "        print(f\"  - {fname} has wrong schema, skip.\")\n",
        "        continue\n",
        "    uniq_pairs = df_sub[[\"leading_item_id\", \"following_item_id\"]].drop_duplicates()\n",
        "    for _, row in uniq_pairs.iterrows():\n",
        "        A = row[\"leading_item_id\"]\n",
        "        B = row[\"following_item_id\"]\n",
        "        pair_appear[(A, B)] += 1\n",
        "        # ë°©í–¥ì„± ìˆëŠ” ë¬¸ì œë¼ (B,A)ëŠ” ë³„ë„ë¡œ ê³„ì‚°\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. pair-level feature ìƒì„±\n",
        "# ============================================================\n",
        "print(\"â–¶ Building pair-level features...\")\n",
        "\n",
        "MAX_LAG = 12\n",
        "\n",
        "def compute_pair_stats(A, B, max_lag=MAX_LAG):\n",
        "    \"\"\"(A,B) ìŒì— ëŒ€í•´ lag 1~max_lag ê¸°ì¤€ ê³µí–‰ì„± ê´€ë ¨ feature ê³„ì‚°\"\"\"\n",
        "    if (A not in panel.columns) or (B not in panel.columns):\n",
        "        return None\n",
        "\n",
        "    sA = panel[A].astype(float)\n",
        "    sB = panel[B].astype(float)\n",
        "\n",
        "    # pct_change\n",
        "    sA_p = sA.pct_change().replace([np.inf, -np.inf], np.nan)\n",
        "    sB_p = sB.pct_change().replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    best_lag = None\n",
        "    best_diff_corr = -999.0\n",
        "    best_level_corr = 0.0\n",
        "    best_n_overlap = 0\n",
        "\n",
        "    for lag in range(1, max_lag+1):\n",
        "        # A_t â†’ B_{t+lag}\n",
        "        a_cut = sA_p.iloc[:-lag]\n",
        "        b_shift = sB_p.shift(-lag).iloc[:-lag]\n",
        "        valid = a_cut.notna() & b_shift.notna()\n",
        "        n_ov = int(valid.sum())\n",
        "        if n_ov < 5:  # ìµœì†Œ 5ê°œ ì´ìƒ ê°™ì´ ìˆì–´ì•¼ ì˜ë¯¸ ìˆë‹¤ê³  ë³´ì\n",
        "            continue\n",
        "\n",
        "        x = a_cut[valid]\n",
        "        y = b_shift[valid]\n",
        "        if x.nunique() <= 1 or y.nunique() <= 1:\n",
        "            continue\n",
        "\n",
        "        corr = np.corrcoef(x, y)[0, 1]\n",
        "        if np.isnan(corr):\n",
        "            continue\n",
        "\n",
        "        # best_lagëŠ” diff_corr ê¸°ì¤€ ìµœëŒ€ê°’\n",
        "        if corr > best_diff_corr:\n",
        "            best_diff_corr = float(corr)\n",
        "            best_lag = lag\n",
        "            # level corrì€ value ê¸°ì¤€ìœ¼ë¡œ ì¬ê³„ì‚°\n",
        "            a_val = sA.iloc[:-lag]\n",
        "            b_val = sB.shift(-lag).iloc[:-lag]\n",
        "            v2 = a_val.notna() & b_val.notna()\n",
        "            if v2.sum() >= 5:\n",
        "                xv = a_val[v2]\n",
        "                yv = b_val[v2]\n",
        "                if xv.nunique() > 1 and yv.nunique() > 1:\n",
        "                    lc = np.corrcoef(xv, yv)[0, 1]\n",
        "                    best_level_corr = float(lc) if not np.isnan(lc) else 0.0\n",
        "                else:\n",
        "                    best_level_corr = 0.0\n",
        "            else:\n",
        "                best_level_corr = 0.0\n",
        "            best_n_overlap = n_ov\n",
        "\n",
        "    # spike_jaccard\n",
        "    # pct_change ê¸°ì¤€ìœ¼ë¡œ |ë³€í™”ìœ¨| í° ë‹¬ì„ spikeë¡œ.\n",
        "    # thresholdëŠ” ìƒìœ„ 20% ì •ë„ë¡œ ì„¤ì • (ë°ì´í„°ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)\n",
        "    def spike_mask(s_p):\n",
        "        s_abs = s_p.abs()\n",
        "        if s_abs.notna().sum() == 0:\n",
        "            return pd.Series(False, index=s_p.index)\n",
        "        thr = s_abs.quantile(0.8)\n",
        "        return s_abs >= thr\n",
        "\n",
        "    maskA = spike_mask(sA_p)\n",
        "    maskB = spike_mask(sB_p)\n",
        "    inter = (maskA & maskB).sum()\n",
        "    union = (maskA | maskB).sum()\n",
        "    spike_jacc = float(inter / union) if union > 0 else 0.0\n",
        "\n",
        "    # seasonal similarity\n",
        "    seas_sim = seasonal_sim(A, B)\n",
        "\n",
        "    # hs similarity\n",
        "    hA = item_hs4.get(A, None)\n",
        "    hB = item_hs4.get(B, None)\n",
        "    hs2A = item_hs2.get(A, None)\n",
        "    hs2B = item_hs2.get(B, None)\n",
        "\n",
        "    same_hs4 = int(hA is not None and hB is not None and str(hA) == str(hB))\n",
        "    same_hs2 = int(hs2A is not None and hs2B is not None and str(hs2A) == str(hs2B))\n",
        "\n",
        "    # hs_similarity ìˆ«ìí˜• (ëŒ€ëµì ì¸ ìŠ¤ì½”ì–´)\n",
        "    if same_hs4:\n",
        "        hs_sim = 1.0\n",
        "    elif same_hs2:\n",
        "        hs_sim = 0.7\n",
        "    else:\n",
        "        hs_sim = 0.0\n",
        "\n",
        "    # active ratio\n",
        "    actA = float(active_ratio.get(A, 0.0))\n",
        "    actB = float(active_ratio.get(B, 0.0))\n",
        "\n",
        "    return dict(\n",
        "        best_lag=best_lag if best_lag is not None else 0,\n",
        "        diff_corr=best_diff_corr if best_lag is not None else 0.0,\n",
        "        level_corr=best_level_corr if best_lag is not None else 0.0,\n",
        "        n_overlap=best_n_overlap,\n",
        "        spike_jaccard=spike_jacc,\n",
        "        seasonal_sim=seas_sim,\n",
        "        same_hs4=same_hs4,\n",
        "        same_hs2=same_hs2,\n",
        "        hs_similarity=hs_sim,\n",
        "        active_A=actA,\n",
        "        active_B=actB,\n",
        "    )\n",
        "\n",
        "\n",
        "pairs = sub[[\"leading_item_id\", \"following_item_id\"]].drop_duplicates()\n",
        "features = []\n",
        "\n",
        "for idx, row in pairs.iterrows():\n",
        "    A = row[\"leading_item_id\"]\n",
        "    B = row[\"following_item_id\"]\n",
        "    stats = compute_pair_stats(A, B, max_lag=MAX_LAG)\n",
        "    if stats is None:\n",
        "        # panelì— ì—†ëŠ” itemì´ ìˆì„ ê²½ìš°\n",
        "        stats = dict(\n",
        "            best_lag=0,\n",
        "            diff_corr=0.0,\n",
        "            level_corr=0.0,\n",
        "            n_overlap=0,\n",
        "            spike_jaccard=0.0,\n",
        "            seasonal_sim=0.0,\n",
        "            same_hs4=0,\n",
        "            same_hs2=0,\n",
        "            hs_similarity=0.0,\n",
        "            active_A=float(active_ratio.get(A, 0.0)),\n",
        "            active_B=float(active_ratio.get(B, 0.0)),\n",
        "        )\n",
        "    stats[\"leading_item_id\"] = A\n",
        "    stats[\"following_item_id\"] = B\n",
        "    stats[\"appear_cnt\"] = pair_appear.get((A, B), 0)\n",
        "    features.append(stats)\n",
        "\n",
        "pair_df = pd.DataFrame(features)\n",
        "print(f\"  - pair_df shape: {pair_df.shape}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. pseudo-label ìƒì„± (signal_score ê¸°ë°˜)\n",
        "# ============================================================\n",
        "print(\"â–¶ Building pseudo-labels...\")\n",
        "\n",
        "# ê²°ì¸¡ ì±„ìš°ê¸°\n",
        "for col in [\"diff_corr\", \"level_corr\", \"spike_jaccard\", \"seasonal_sim\", \"hs_similarity\"]:\n",
        "    pair_df[col] = pair_df[col].fillna(0.0)\n",
        "\n",
        "# ê³µí–‰ì„± ì‹ í˜¸ ì ìˆ˜ (ê°€ì¤‘í•©ì€ í•„ìš”í•˜ë©´ ì¡°ì • ê°€ëŠ¥)\n",
        "pair_df[\"signal_score\"] = (\n",
        "    0.5 * pair_df[\"diff_corr\"] +\n",
        "    0.2 * pair_df[\"level_corr\"] +\n",
        "    0.2 * pair_df[\"spike_jaccard\"] +\n",
        "    0.1 * pair_df[\"seasonal_sim\"] +\n",
        "    0.1 * pair_df[\"hs_similarity\"]\n",
        ")\n",
        "\n",
        "high_q = pair_df[\"signal_score\"].quantile(0.80)  # ìƒìœ„ 20%\n",
        "low_q  = pair_df[\"signal_score\"].quantile(0.20)  # í•˜ìœ„ 20%\n",
        "\n",
        "pair_df[\"pseudo_label\"] = -1  # -1ì€ í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ\n",
        "\n",
        "# ê°• ì–‘ì„±: signal_score ìƒìœ„ + ë˜ëŠ” ì´ì „ ì œì¶œì—ì„œ ë“±ì¥\n",
        "pos_mask = (\n",
        "    (pair_df[\"signal_score\"] >= high_q) |\n",
        "    (pair_df[\"appear_cnt\"] >= 1)\n",
        ")\n",
        "\n",
        "# ê°• ìŒì„±: signal_score í•˜ìœ„ + appear_cnt == 0\n",
        "neg_mask = (\n",
        "    (pair_df[\"signal_score\"] <= low_q) &\n",
        "    (pair_df[\"appear_cnt\"] == 0)\n",
        ")\n",
        "\n",
        "pair_df.loc[pos_mask, \"pseudo_label\"] = 1\n",
        "pair_df.loc[neg_mask, \"pseudo_label\"] = 0\n",
        "\n",
        "n_pos = int((pair_df[\"pseudo_label\"] == 1).sum())\n",
        "n_neg = int((pair_df[\"pseudo_label\"] == 0).sum())\n",
        "n_used = int((pair_df[\"pseudo_label\"] >= 0).sum())\n",
        "print(f\"  - #pseudo positive: {n_pos}\")\n",
        "print(f\"  - #pseudo negative: {n_neg}\")\n",
        "print(f\"  - pseudo-labeled pairs total: {n_used}\")\n",
        "\n",
        "pseudo_df = pair_df[pair_df[\"pseudo_label\"] >= 0].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. LightGBM ë¶„ë¥˜ê¸° í•™ìŠµ (ê³µí–‰ì„±ìŒ íŒë³„)\n",
        "# ============================================================\n",
        "print(\"â–¶ Training pair classification model (LightGBM)...\")\n",
        "\n",
        "CLF_PARAMS = dict(\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    max_depth=-1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    min_data_in_leaf=20,\n",
        "    reg_lambda=1.0,\n",
        "    reg_alpha=0.0,\n",
        "    objective=\"binary\",\n",
        "    random_state=SEED,\n",
        "    force_row_wise=True,\n",
        "    verbosity=-1,\n",
        ")\n",
        "\n",
        "clf_features = [\n",
        "    \"best_lag\",\n",
        "    \"diff_corr\",\n",
        "    \"level_corr\",\n",
        "    \"n_overlap\",\n",
        "    \"spike_jaccard\",\n",
        "    \"seasonal_sim\",\n",
        "    \"active_A\",\n",
        "    \"active_B\",\n",
        "    \"hs_similarity\",\n",
        "    \"same_hs4\",\n",
        "    \"same_hs2\",\n",
        "    # appear_cntëŠ” featureì—ì„œ ì œê±°! (ë¼ë²¨ ë§Œë“¤ ë•Œë§Œ ì‚¬ìš©)\n",
        "]\n",
        "\n",
        "X_clf = pseudo_df[clf_features].copy()\n",
        "y_clf = pseudo_df[\"pseudo_label\"].astype(int)\n",
        "\n",
        "X_clf = X_clf.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "oof_pred = np.zeros(len(X_clf))\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_clf, y_clf), 1):\n",
        "    X_tr, X_va = X_clf.iloc[tr_idx], X_clf.iloc[va_idx]\n",
        "    y_tr, y_va = y_clf.iloc[tr_idx], y_clf.iloc[va_idx]\n",
        "\n",
        "    clf = LGBMClassifier(**CLF_PARAMS)\n",
        "    clf.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_va, y_va)],\n",
        "        eval_metric=\"binary_logloss\",\n",
        "        callbacks=[\n",
        "            early_stopping(stopping_rounds=100, verbose=False),\n",
        "            log_evaluation(period=0),\n",
        "        ],\n",
        "    )\n",
        "    oof_pred[va_idx] = clf.predict_proba(X_va)[:, 1]\n",
        "\n",
        "print(f\"  - OOF AUC = {roc_auc_score(y_clf, oof_pred):.4f}\")\n",
        "print(f\"  - OOF AP  = {average_precision_score(y_clf, oof_pred):.4f}\")\n",
        "\n",
        "# ì „ì²´ pseudo ë¼ë²¨ë¡œ ìµœì¢… í•™ìŠµ\n",
        "clf_final = LGBMClassifier(**CLF_PARAMS)\n",
        "clf_final.fit(X_clf, y_clf)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. ì „ì²´ 9900ìŒì— ëŒ€í•´ ê³µí–‰ì„± í™•ë¥  ì˜ˆì¸¡\n",
        "# ============================================================\n",
        "print(\"â–¶ Predicting comovement probability for all pairs...\")\n",
        "\n",
        "X_all_pairs = pair_df[clf_features].copy()\n",
        "X_all_pairs = X_all_pairs.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "pair_df[\"comov_prob\"] = clf_final.predict_proba(X_all_pairs)[:, 1]\n",
        "print(pair_df[\"comov_prob\"].describe())\n",
        "\n",
        "# ê²°ê³¼ ì €ì¥: ê³µí–‰ì„± í™•ë¥  + ëª¨ë“  pair-level featureê¹Œì§€ ê°™ì´ ì €ì¥\n",
        "out_prob_path = \"pair_comov_prob_full.csv\"\n",
        "pair_df.to_csv(out_prob_path, index=False)\n",
        "print(f\"â–¶ Saved pair features + prob: {out_prob_path}, shape={pair_df.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb4esbgySrtq",
        "outputId": "ed579fd9-806b-4e86-8799-e75cd426033b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â–¶ Loading data...\n",
            "  - panel shape = (43, 100)\n",
            "â–¶ Loading previous submissions for appear_cnt...\n",
            "â–¶ Building pair-level features...\n",
            "  - pair_df shape: (9900, 14)\n",
            "â–¶ Building pseudo-labels...\n",
            "  - #pseudo positive: 4134\n",
            "  - #pseudo negative: 1546\n",
            "  - pseudo-labeled pairs total: 5680\n",
            "â–¶ Training pair classification model (LightGBM)...\n",
            "  - OOF AUC = 0.9585\n",
            "  - OOF AP  = 0.9866\n",
            "â–¶ Predicting comovement probability for all pairs...\n",
            "count    9900.000000\n",
            "mean        0.816455\n",
            "std         0.360236\n",
            "min         0.000094\n",
            "25%         0.945612\n",
            "50%         0.999971\n",
            "75%         1.000000\n",
            "max         1.000000\n",
            "Name: comov_prob, dtype: float64\n",
            "â–¶ Saved pair features + prob: pair_comov_prob_full.csv, shape=(9900, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# KMU Comovement â€” Pair Classifier ê²°ê³¼ ê¸°ë°˜ íšŒê·€ + ì œì¶œ ìƒì„±\n",
        "#  - ì…ë ¥: train.csv, sample_submission.csv, pair_comov_prob.csv\n",
        "#  - ì¶œë ¥: submission.csv (ì„ íƒëœ ê³µí–‰ì„±ìŒì— ëŒ€í•´ 2025-08 value ì˜ˆì¸¡)\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "from sklearn.model_selection import KFold\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "DATA_DIR = Path(\".\")\n",
        "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
        "SUB_PATH   = DATA_DIR / \"sample_submission.csv\"\n",
        "PAIR_PROB_PATH = DATA_DIR / \"pair_comov_prob_full.csv\"\n",
        "\n",
        "# ğŸ”§ ê³µí–‰ì„±ìŒìœ¼ë¡œ ì“¸ ìƒìœ„ Nê°œ (ì¤‘ìš”!)\n",
        "TOP_N = 2400   # 1800~2600 ì‚¬ì´ ì •ë„ë¥¼ ì™”ë‹¤ê°”ë‹¤ í•˜ë©´ì„œ íŠœë‹í•´ë³¼ ìˆ˜ ìˆìŒ\n",
        "\n",
        "# LightGBM íšŒê·€ íŒŒë¼ë¯¸í„°\n",
        "REG_PARAMS = dict(\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=63,\n",
        "    max_depth=-1,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    min_data_in_leaf=25,\n",
        "    min_sum_hessian_in_leaf=1.0,\n",
        "    reg_lambda=1.0,\n",
        "    reg_alpha=0.1,\n",
        "    objective=\"rmse\",\n",
        "    random_state=SEED,\n",
        "    force_row_wise=True,\n",
        "    verbosity=-1,\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 1. ë°ì´í„° ë¡œë“œ + ì›”ë³„ íŒ¨ë„ ìƒì„±\n",
        "# ============================================================\n",
        "print(\"â–¶ Loading data...\")\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "sub   = pd.read_csv(SUB_PATH)\n",
        "pair_df = pd.read_csv(PAIR_PROB_PATH)\n",
        "\n",
        "assert {\"item_id\", \"year\", \"month\", \"value\"}.issubset(train.columns)\n",
        "assert {\"leading_item_id\",\"following_item_id\",\"comov_prob\"}.issubset(pair_df.columns)\n",
        "\n",
        "# year-month â†’ date\n",
        "train[\"date\"] = pd.to_datetime(\n",
        "    dict(year=train[\"year\"], month=train[\"month\"], day=1)\n",
        ")\n",
        "\n",
        "# ì›”ë³„ value í•©\n",
        "monthly = (\n",
        "    train.groupby([\"item_id\",\"date\"], as_index=False)[\"value\"]\n",
        "         .sum()\n",
        ")\n",
        "\n",
        "# íŒ¨ë„: index=date, columns=item_id\n",
        "panel = monthly.pivot(index=\"date\", columns=\"item_id\", values=\"value\").sort_index()\n",
        "print(f\"  - panel shape = {panel.shape}\")  # (n_months, n_items)\n",
        "\n",
        "dates = panel.index.to_list()\n",
        "items = panel.columns.to_list()\n",
        "n_months = len(dates)\n",
        "\n",
        "# ìµœê·¼ ë‹¬ì´ 2025-07ì¸ì§€ í™•ì¸\n",
        "print(\"  - date range:\", dates[0], \"~\", dates[-1])\n",
        "\n",
        "# ============================================================\n",
        "# 2. comov_prob ê¸°ì¤€ ìƒìœ„ Nê°œ ìŒ ì„ íƒ\n",
        "# ============================================================\n",
        "print(\"â–¶ Selecting top-N comovement pairs...\")\n",
        "pair_sorted = pair_df.sort_values(\"comov_prob\", ascending=False).reset_index(drop=True)\n",
        "candidates = pair_sorted.head(TOP_N).copy()\n",
        "\n",
        "print(f\"  - TOP_N = {TOP_N}\")\n",
        "print(f\"  - selected candidate pairs: {len(candidates)}\")\n",
        "\n",
        "# best_lagê°€ ì—†ëŠ” ê²½ìš°(0 ë˜ëŠ” NaN)ëŠ” ìµœì†Œ 1ë¡œ ë³´ì •\n",
        "candidates[\"best_lag\"] = candidates[\"best_lag\"].fillna(0).astype(int)\n",
        "candidates.loc[candidates[\"best_lag\"] <= 0, \"best_lag\"] = 1\n",
        "\n",
        "# ============================================================\n",
        "# 3. íšŒê·€ í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±\n",
        "# ============================================================\n",
        "print(\"â–¶ Building regression dataset for B(t+1) prediction...\")\n",
        "\n",
        "rows = []\n",
        "\n",
        "for idx, row in candidates.iterrows():\n",
        "    A = row[\"leading_item_id\"]\n",
        "    B = row[\"following_item_id\"]\n",
        "    lag = int(row[\"best_lag\"])\n",
        "\n",
        "    if (A not in panel.columns) or (B not in panel.columns):\n",
        "        continue\n",
        "\n",
        "    sA = panel[A].fillna(0.0).values.astype(float)\n",
        "    sB = panel[B].fillna(0.0).values.astype(float)\n",
        "\n",
        "    # ë¡œê·¸ ìŠ¤ì¼€ì¼ê°’ (ìŠ¤ì¼€ì¼ ì•ˆì •í™”ìš©)\n",
        "    sA_log = np.log1p(np.clip(sA, 0, None))\n",
        "    sB_log = np.log1p(np.clip(sB, 0, None))\n",
        "\n",
        "    for t in range(n_months - 1):\n",
        "        # targetì€ B_{t+1}\n",
        "        if t + 1 >= n_months:\n",
        "            continue\n",
        "        # lag, ê³¼ê±° 3ê°œì›” ë“±ì„ í™•ë³´í•´ì•¼ í•˜ë¯€ë¡œ ì¸ë±ìŠ¤ ì²´í¬\n",
        "        if t - lag < 0 or t - 1 < 0:\n",
        "            continue\n",
        "\n",
        "        # B í˜„ì¬/ê³¼ê±°\n",
        "        b_t      = sB_log[t]\n",
        "        b_t_1    = sB_log[t-1]\n",
        "        b_t_2    = sB_log[t-2] if t >= 2 else 0.0\n",
        "        b_t_3    = sB_log[t-3] if t >= 3 else 0.0\n",
        "\n",
        "        # A ë¦¬ë“œ ê°’ (lag ë°˜ì˜: A_{t-lag})\n",
        "        a_t_lag  = sA_log[t - lag]\n",
        "        a_t_lag1 = sA_log[t - lag - 1] if (t - lag - 1) >= 0 else 0.0\n",
        "\n",
        "        # ì´ë™ í‰ê·  (log ê°’ ê¸°ì¤€)\n",
        "        b_ma3 = sB_log[max(0, t-2):t+1].mean()\n",
        "        b_ma6 = sB_log[max(0, t-5):t+1].mean()\n",
        "        a_ma3 = sA_log[max(0, t-2):t+1].mean()\n",
        "\n",
        "        # MoM (ì„ í˜• ìŠ¤ì¼€ì¼ ê¸°ì¤€ì—ì„œ ê·¼ì‚¬)\n",
        "        b_prev_lin = sB[t-1] if t-1 >= 0 else 0.0\n",
        "        b_curr_lin = sB[t]\n",
        "        if b_prev_lin > 0:\n",
        "            b_mom = (b_curr_lin - b_prev_lin) / (b_prev_lin + 1e-6)\n",
        "        else:\n",
        "            b_mom = 0.0\n",
        "\n",
        "        a_prev_lin = sA[t-lag-1] if (t-lag-1) >= 0 else 0.0\n",
        "        a_curr_lin = sA[t-lag] if (t-lag) >= 0 else 0.0\n",
        "        if a_prev_lin > 0:\n",
        "            a_mom = (a_curr_lin - a_prev_lin) / (a_prev_lin + 1e-6)\n",
        "        else:\n",
        "            a_mom = 0.0\n",
        "\n",
        "        # ë‹¬/ì—° íš¨ê³¼\n",
        "        dt_t = dates[t]   # pandas.Timestamp\n",
        "        month = dt_t.month\n",
        "        year_effect = dt_t.year - 2022  # 2022 ê¸°ì¤€ offset\n",
        "\n",
        "        # íƒ€ê¹ƒ(B_{t+1}) log1p\n",
        "        target_lin = sB[t+1]\n",
        "        target_log = np.log1p(np.clip(target_lin, 0, None))\n",
        "\n",
        "        rows.append({\n",
        "            \"leading_item_id\": A,\n",
        "            \"following_item_id\": B,\n",
        "            \"date_idx\": t,   # ì‹œê°„ ìˆœì„œë¥¼ ìœ„í•œ ì¸ë±ìŠ¤\n",
        "            \"b_t\": b_t,\n",
        "            \"b_t_1\": b_t_1,\n",
        "            \"b_t_2\": b_t_2,\n",
        "            \"b_t_3\": b_t_3,\n",
        "            \"a_t_lag\": a_t_lag,\n",
        "            \"a_t_lag1\": a_t_lag1,\n",
        "            \"b_ma3\": b_ma3,\n",
        "            \"b_ma6\": b_ma6,\n",
        "            \"a_ma3\": a_ma3,\n",
        "            \"b_mom\": b_mom,\n",
        "            \"a_mom\": a_mom,\n",
        "            \"best_lag\": float(lag),\n",
        "            \"comov_prob\": float(row[\"comov_prob\"]),\n",
        "            \"month\": month,\n",
        "            \"year_effect\": year_effect,\n",
        "            \"target\": target_log,\n",
        "        })\n",
        "\n",
        "reg_df = pd.DataFrame(rows)\n",
        "print(f\"  - regression dataset shape: {reg_df.shape}\")\n",
        "\n",
        "if reg_df.empty:\n",
        "    raise RuntimeError(\"íšŒê·€ í•™ìŠµ ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. TOP_N ë˜ëŠ” lag ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "# ============================================================\n",
        "# 4. íšŒê·€ ëª¨ë¸ í•™ìŠµ (ê°„ë‹¨í•œ ì‹œê°„ê¸°ë°˜ CV)\n",
        "# ============================================================\n",
        "print(\"â–¶ Training regression model (LightGBM)...\")\n",
        "\n",
        "feature_cols = [\n",
        "    \"b_t\",\"b_t_1\",\"b_t_2\",\"b_t_3\",\n",
        "    \"a_t_lag\",\"a_t_lag1\",\n",
        "    \"b_ma3\",\"b_ma6\",\"a_ma3\",\n",
        "    \"b_mom\",\"a_mom\",\n",
        "    \"best_lag\",\n",
        "    \"comov_prob\",\n",
        "    \"month\",\"year_effect\",\n",
        "]\n",
        "\n",
        "X_reg = reg_df[feature_cols].replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "y_reg = reg_df[\"target\"].values\n",
        "date_idx = reg_df[\"date_idx\"].values\n",
        "\n",
        "# ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ìˆœí•œ ì‹œê°„ ê¸°ë°˜ KFold ë‚˜ëˆ„ê¸°\n",
        "unique_t = sorted(np.unique(date_idx))\n",
        "n_splits = 4\n",
        "splits = np.array_split(unique_t, n_splits)\n",
        "\n",
        "oof_pred = np.zeros(len(reg_df))\n",
        "\n",
        "for fold, va_times in enumerate(splits, 1):\n",
        "    va_mask = np.isin(date_idx, va_times)\n",
        "    tr_mask = ~va_mask\n",
        "\n",
        "    X_tr, X_va = X_reg[tr_mask], X_reg[va_mask]\n",
        "    y_tr, y_va = y_reg[tr_mask], y_reg[va_mask]\n",
        "\n",
        "    reg = LGBMRegressor(**REG_PARAMS)\n",
        "    reg.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_va, y_va)],\n",
        "        eval_metric=\"rmse\",\n",
        "        callbacks=[\n",
        "            early_stopping(stopping_rounds=100, verbose=False),\n",
        "            log_evaluation(period=0),\n",
        "        ],\n",
        "    )\n",
        "    oof_pred[va_mask] = reg.predict(X_va)\n",
        "\n",
        "rmse_oof = np.sqrt(np.mean((oof_pred - y_reg)**2))\n",
        "print(f\"  - OOF RMSE (log1p scale) = {rmse_oof:.4f}\")\n",
        "\n",
        "# ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… í•™ìŠµ\n",
        "reg_final = LGBMRegressor(**REG_PARAMS)\n",
        "reg_final.fit(X_reg, y_reg, callbacks=[log_evaluation(period=0)])\n",
        "\n",
        "# ============================================================\n",
        "# 5. 2025-08 ì˜ˆì¸¡ (t=2025-07 ê¸°ì¤€)\n",
        "# ============================================================\n",
        "print(\"â–¶ Predicting 2025-08 values for selected pairs...\")\n",
        "\n",
        "t_last = n_months - 1  # ë§ˆì§€ë§‰ ë‹¬ index (ì•„ë§ˆ 2025-07)\n",
        "dt_last = dates[t_last]\n",
        "print(\"  - last observed month:\", dt_last)\n",
        "\n",
        "pred_dict = {}\n",
        "\n",
        "for idx, row in candidates.iterrows():\n",
        "    A = row[\"leading_item_id\"]\n",
        "    B = row[\"following_item_id\"]\n",
        "    lag = int(row[\"best_lag\"])\n",
        "    prob = float(row[\"comov_prob\"])\n",
        "\n",
        "    if (A not in panel.columns) or (B not in panel.columns):\n",
        "        continue\n",
        "\n",
        "    sA = panel[A].fillna(0.0).values.astype(float)\n",
        "    sB = panel[B].fillna(0.0).values.astype(float)\n",
        "    sA_log = np.log1p(np.clip(sA, 0, None))\n",
        "    sB_log = np.log1p(np.clip(sB, 0, None))\n",
        "\n",
        "    t = t_last  # t ê¸°ì¤€ìœ¼ë¡œ t+1(=2025-08)ì„ ì˜ˆì¸¡\n",
        "    if t - lag < 0 or t - 1 < 0:\n",
        "        # lag ë•Œë¬¸ì— featureê°€ ì•ˆë‚˜ì˜¤ë©´ B_last ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
        "        yhat_lin = float(sB[t])\n",
        "        yhat = max(0.0, yhat_lin)\n",
        "        yhat = int(round(yhat))\n",
        "        pred_dict[(A,B)] = yhat\n",
        "        continue\n",
        "\n",
        "    b_t      = sB_log[t]\n",
        "    b_t_1    = sB_log[t-1]\n",
        "    b_t_2    = sB_log[t-2] if t >= 2 else 0.0\n",
        "    b_t_3    = sB_log[t-3] if t >= 3 else 0.0\n",
        "\n",
        "    a_t_lag  = sA_log[t - lag]\n",
        "    a_t_lag1 = sA_log[t - lag - 1] if (t - lag - 1) >= 0 else 0.0\n",
        "\n",
        "    b_ma3 = sB_log[max(0, t-2):t+1].mean()\n",
        "    b_ma6 = sB_log[max(0, t-5):t+1].mean()\n",
        "    a_ma3 = sA_log[max(0, t-2):t+1].mean()\n",
        "\n",
        "    b_prev_lin = sB[t-1] if t-1 >= 0 else 0.0\n",
        "    b_curr_lin = sB[t]\n",
        "    if b_prev_lin > 0:\n",
        "        b_mom = (b_curr_lin - b_prev_lin) / (b_prev_lin + 1e-6)\n",
        "    else:\n",
        "        b_mom = 0.0\n",
        "\n",
        "    a_prev_lin = sA[t-lag-1] if (t-lag-1) >= 0 else 0.0\n",
        "    a_curr_lin = sA[t-lag] if (t-lag) >= 0 else 0.0\n",
        "    if a_prev_lin > 0:\n",
        "        a_mom = (a_curr_lin - a_prev_lin) / (a_prev_lin + 1e-6)\n",
        "    else:\n",
        "        a_mom = 0.0\n",
        "\n",
        "    month = 8                 # ì˜ˆì¸¡ ëŒ€ìƒ: 8ì›”\n",
        "    year_effect = 2025 - 2022\n",
        "\n",
        "    feat_vec = {\n",
        "        \"b_t\": b_t,\n",
        "        \"b_t_1\": b_t_1,\n",
        "        \"b_t_2\": b_t_2,\n",
        "        \"b_t_3\": b_t_3,\n",
        "        \"a_t_lag\": a_t_lag,\n",
        "        \"a_t_lag1\": a_t_lag1,\n",
        "        \"b_ma3\": b_ma3,\n",
        "        \"b_ma6\": b_ma6,\n",
        "        \"a_ma3\": a_ma3,\n",
        "        \"b_mom\": b_mom,\n",
        "        \"a_mom\": a_mom,\n",
        "        \"best_lag\": float(lag),\n",
        "        \"comov_prob\": prob,\n",
        "        \"month\": month,\n",
        "        \"year_effect\": year_effect,\n",
        "    }\n",
        "\n",
        "    X_test = pd.DataFrame([feat_vec])[feature_cols].replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "    y_log = float(reg_final.predict(X_test)[0])\n",
        "    y_lin = np.expm1(y_log)\n",
        "    if not np.isfinite(y_lin):\n",
        "        y_lin = float(sB[t])\n",
        "\n",
        "    y_lin = max(0.0, y_lin)\n",
        "    yhat = int(round(y_lin))\n",
        "\n",
        "    pred_dict[(A,B)] = yhat\n",
        "\n",
        "print(f\"  - predicted pairs: {len(pred_dict)}\")\n",
        "\n",
        "# ============================================================\n",
        "# 6. submission.csv ìƒì„± (ì„ íƒëœ ìŒë§Œ)\n",
        "# ============================================================\n",
        "print(\"â–¶ Building submission file...\")\n",
        "\n",
        "rows_out = []\n",
        "cand_keys = set(pred_dict.keys())\n",
        "\n",
        "for _, row in sub.iterrows():\n",
        "    A = row[\"leading_item_id\"]\n",
        "    B = row[\"following_item_id\"]\n",
        "    key = (A,B)\n",
        "    if key not in cand_keys:\n",
        "        # ê³µí–‰ì„±ìŒìœ¼ë¡œ ì„ íƒë˜ì§€ ì•Šì€ ê±´ ì œì¶œí•˜ì§€ ì•ŠìŒ\n",
        "        continue\n",
        "    rows_out.append({\n",
        "        \"leading_item_id\": A,\n",
        "        \"following_item_id\": B,\n",
        "        \"value\": pred_dict[key],\n",
        "    })\n",
        "\n",
        "sub_out = pd.DataFrame(rows_out,\n",
        "                       columns=[\"leading_item_id\",\"following_item_id\",\"value\"])\n",
        "sub_out.to_csv(\"submission.csv\", index=False)\n",
        "print(f\"â–¶ Saved submission: submission.csv shape= {sub_out.shape}\")\n",
        "print(sub_out.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXLK5RqC0Fi5",
        "outputId": "818d98e6-1a27-4a33-bae3-c0bc00005f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â–¶ Loading data...\n",
            "  - panel shape = (43, 100)\n",
            "  - date range: 2022-01-01 00:00:00 ~ 2025-07-01 00:00:00\n",
            "â–¶ Selecting top-N comovement pairs...\n",
            "  - TOP_N = 2400\n",
            "  - selected candidate pairs: 2400\n",
            "â–¶ Building regression dataset for B(t+1) prediction...\n",
            "  - regression dataset shape: (83338, 19)\n",
            "â–¶ Training regression model (LightGBM)...\n",
            "  - OOF RMSE (log1p scale) = 1.8948\n",
            "â–¶ Predicting 2025-08 values for selected pairs...\n",
            "  - last observed month: 2025-07-01 00:00:00\n",
            "  - predicted pairs: 2400\n",
            "â–¶ Building submission file...\n",
            "â–¶ Saved submission: submission.csv shape= (2400, 3)\n",
            "  leading_item_id following_item_id    value\n",
            "0        DEWLVASR          AHMDUILJ    81309\n",
            "1        DEWLVASR          XMKRPGLB   724545\n",
            "2        DEWLVASR          ZKENOUDA   354698\n",
            "3        DEWLVASR          LLHREMKS    40340\n",
            "4        DEWLVASR          WPQXWHYO  9139203\n"
          ]
        }
      ]
    }
  ]
}